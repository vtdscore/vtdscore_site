---
title: Linear Regression with the Marbles Dataset
author: Jeffrey Brabec
date: '2020-06-22'
slug: linear-regression-with-the-marbles-dataset
categories:
  - Statistics
  - TidyTuesday
tags:
  - tidymodels
  - tidyverse
---
## Setting Up
```{r echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)

#This will read the marbles.csv directly into your environment -->
marbles <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-06-02/marbles.csv')
```

## Reviewing Last Week

In our previous sesion we did some exploratory data analysis of last week's TidyTuesday data set which had race information from the previous season of [Jelle's Marble Runs](https://www.youtube.com/channel/UCYJdpnjuSWVOLgGT9fIzL0g). The data included information on the place of each marble in the 8 races of the season, individual marble names, lap times, and the number of points earned for finishing place.

We took the data that was provided and we used a few data wrangling tricks to add five additional columns. The first two columns, `points_sum` and `points_cum` tracked the total number of points earned by a team at the end of the season and the cumulative points earned after each race. These two additional columns allowed us to then calculate the rank of each team at the end of a race, and the final overall rank of the teams at the end of the season. 

We also added a column that just lists the race number (`race_num`) instead of the "S#R#" format used by the dataset and another that contains abbreviated team names (`team_abbr`). 
```{r eval=TRUE, message=FALSE}
marbles_rank <- marbles %>% 
  select(race, marble_name, team_name, points, time_s, pole) %>% #Selects a specific subset of columns
  filter(str_detect(race, "R")) %>% #Filters the rows of your data.frame to only include races that determine end of season ranking
  group_by(race, team_name) %>% 
  summarize(points = unique(points)) %>% 
  group_by(team_name) %>% 
  arrange(team_name, race) %>% 
  mutate( #this step adds to new columns called points_sum and points_cumulative
    points_sum = sum(points), #total points at the end of the season
    points_cumulative = cumsum(points) #The sum of points for a team after each race
  ) %>% 
  group_by(race) %>% 
  arrange(-points_cumulative, points_sum) %>% #sort your rows so that the highest scoring team is at the top
  mutate(rank = row_number()) %>% #calculate rank based on row_number of a team
  ungroup() %>% #we've grouped a lot of data here but be sure to ungroup it all before doing any kind of plotting! You'll get some funky looking figures
  mutate( #here we're adding two new columns and changing the factor levels of another
    race_num = as.numeric(str_remove(race, "S1R")), #making a column that just lists the race number
    team_name = fct_reorder(team_name, -points_sum), #This is reordering the factor levels of the team_name column. I can go into a deeper explanation in our next session
    team_abbr = case_when( #since the team names are long and will make a plot misshapen, we're going to make a column with team abbreviations
      team_name == "Savage Speeders" ~ "SAV",
      team_name == "Hazers" ~ "HAZ",
      team_name == "O'rangers" ~ "ORA",
      team_name == "Snowballs" ~ "SNO",
      team_name == "Green Ducks" ~ "GDK",
      team_name == "Team Galactic" ~ "TGL",
      team_name == "Team Primary" ~ "TPR",
      team_name == "Team Momo" ~ "TMO",
      team_name == "Thunderbolts" ~ "TDB",
      team_name == "Balls of Chaos" ~ "BOC",
      team_name == "Mellow Yellow" ~ "MYL",
      team_name == "Midnight Wisps" ~ "MNW",
      team_name == "Rojo Rollers" ~ "RJR",
      team_name == "Raspberry Racers" ~ "RBR",
      team_name == "Limers" ~ "LMR",
      team_name == "Hornets" ~ "HOR"
    )
  )
```

After we cleaned our data I used a plotting workflow I found on [GitHub](https://github.com/Z3tt/TidyTuesday/blob/master/R/2020_23_MarbleRaces.Rmd) to generate our final figure:
```{r echo=FALSE}
knitr::include_graphics("~/Documents/data_science_group/Images/marble_rankings.png")
```

This figure nicely illustrates how team rankings changed from race to race. But after seeing how drastically some of the rankings changed over the course of the season, I was left with some questions:

1. How important is the final race in determining a team's overall ranking for the season?

1. Does performance in the initial race predict performance in the final race (and rank at the end of the season)?

1. How does starting position affect finishing place in a race?

Today, we're going to try to answer all of these questions using a relationship modeling method called [Linear Regression](https://en.wikipedia.org/wiki/Linear_regression).

## Linear Regression

Before we dive into the regression analysis there is a bit more data wrangling that we need to do. First I want to make sure that I have the starting position (`pole` in the data) of each marble for each race, which is determined by their qualifying lap time. The `pole` position is only listed in the qualifying race rows while all the other information I care about is in the actual race rows. I need to remedy that before I move on.

```{r getting starting positions}
####USE INNERJOIN HERE ALONG WITH THIS METHOD
quals <- marbles %>% 
  select(race, team_name, marble_name, points, time_s, pole, site) %>% 
  filter(str_detect(race, "Q")) %>% 
  group_by(race, team_name) %>% 
  arrange(race, team_name)

start_and_finish <- marbles_rank %>% 
  arrange(race, as.character(team_name)) %>% 
  mutate(start_pos = as.numeric(str_remove(quals$pole, "P")), site = quals$site)

```

```{r eval=TRUE, echo=FALSE}
knitr::kable(head(start_and_finish), caption = "Race Data with Starting Position")
```

## Visual Exploration
Before we start throwing linear regression models around whilly nilly lets take a look at the relationships we want to model. This serves a dual purpose: 1) it allows us to *literally* see the relationships we want to analyze, and 2) it gives us an opportunity to explore other relationships we might not have previously considered examining. 

### What does it look like when we plot all the races together?
```{r}

start_and_finish %>% 
  ggplot(aes(start_pos, rank)) + 
  geom_point(aes(color = team_abbr)) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Starting Position",
       y = "Finishing Place",
       color = "Team")
```

Not the cleanest linear relationship I've ever seen... but let's build a model and see!

To do this we're going to use a new family of "tidy" packages called [tidymodels](https://www.tidymodels.org). Like the `tidyverse` this collection of functions make doing statistical analyses and modeling easier, the syntax more intuitive, and the output cleaner. This is very new to me so we'll be learning this functions together!

First we'll need to define teh model that we care about. In this case we want to model how starting or pole position affects a marble's finishing rank in the race:
```{r}
#First let's define the model we care about
rank ~ start_pos
```

We've seen the tilde before. In this case we're using it to create a model object and we can read it as *rank depends on starting position*. 

To define the methodology we want to use we'll implement some functions from the [parsnip](https://parsnip.tidymodels.org) package. This package takes model building and lets you organically define the various parameters without having to deal with the clunky base R functions. Stay tuned for future sessions when this definition gets better!
```{r}
#We want to specify our model type by declaring it:
linear_reg()
```

Doing this really has no functionality. Its akin to just typing `ggplot`. It just provides important information that downstream functions need to plot properly but doesn't do anything itself.

To define the thing that will be fitting the model we need to specify and **engine**. We'll be using the `lm` engine:

```{r}
linear_reg() %>% 
  set_engine("lm")
```

And we can save this as a model object which we'll call `lm_rank_mod`.
```{r eval=TRUE}
lm_rank_mod <- 
  linear_reg() %>% 
  set_engine("lm")
```

Now we can actually fit our model by passing our model object to the `fit` function:
```{r eval=TRUE, echo=TRUE}
lm_rank_fit <- 
  lm_rank_mod %>% 
  fit(rank ~ start_pos, data = start_and_finish)
lm_rank_fit
```
This is great! We were able to fit the model and we have a coefficient out for starting position. This output doesn't tell us anything important about this relationship though. To get something a little more informative we're going to use the `tidy()` function from the `yardstick` package which creates a more informative and cleaner output of the model results:

```{r eval=TRUE, echo=TRUE}
tidy(lm_rank_fit)
```

From this output we can see that the starting position does have an effect on finishing place and it is significant!

**All other variables held constant, if a marble with a starting position one place better than a competitor will finish .27 places ahead of that competitor** 

Which is more than enough to eek out a win! But this model looks at one variable, pole position, and assumes all other variables are constant... which they aren't. 


Each race is held at a different location and with different racers and that introduces a lot of confounding variables into the equation. So while there is a significant effect with starting position, we might also want to consider the race location as well. Let's do some exploratory data visualization and see!

### Let's start by examining the relationshiop in race 1. We want to query the relationship between starting position and final place.
```{r}

start_and_finish %>% 
  filter(race_num == 1) %>% 
  ggplot(aes(start_pos, rank)) + 
  geom_point(aes(color = team_abbr)) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Starting Position",
       y = "Finishing Place",
       color = "Team")
```

That looks about as strong a relationship as we saw plotting all the races together. Does that linearly relationship hold up across all of the races?

### Let's look at the relationship between starting position and final placement in all of the races.
```{r}
start_and_finish %>% 
  ggplot(aes(start_pos, rank)) +
  geom_point(aes(color = team_abbr)) +
  #geom_abline() +
  geom_smooth(method='lm', formula = y ~ x, se = FALSE) +
  facet_wrap(~fct_inorder(site), nrow = 2, ncol = 4) +
  labs(x = "Starting Position",
       y = "Finishing Position",
       color = "Team",
       title = "Examining the relationship between Pole Position and Finishing Place")
```

This plot, in addition to the zoomed in single race plot, is a great visualization of the linear relationships between starting and ending place in each race. Just looking at this figure we can see that the linear relationship between starting and finishing positions varies drastically. Let's add race number into our model.

```{r eval=FALSE}
#Define the model formula we want to analyze:
rank ~ start_pos + site + site*start_pos
```

This is a more complicated formula than last time! Not only do we want to consider race_number as its own explanatory variable, we also want to see if there is an interaction effect between starting position and race number which is indicated by the `*`.

Before we can run this model however, we need to convert the "Race" location to a numeric variable so that we can us it in the linear model. This variable has 8 different categories which we need to code into something called a **dummy variable**. Categorical variables have to be coded as `1` or `0` if you're transferring it to a numeric value. So when working with something with more variables R has to build something called a **contrast matrix**. Check out the example in [this article](http://www.sthda.com/english/articles/40-regression-analysis/163-regression-with-categorical-variables-dummy-coding-essentials-in-r/). 

To make this contrast matrix we'll be implementing the `recipes` package which has several tools for building models incrementally and with intent. fAll a recipe does is specify what exactly should be done with the data. It doesn't actually do any kind of calculations!
```{r}
marbles_rank_rec <- 
  recipe(rank ~ start_pos + site, data = start_and_finish) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_interact(terms = ~ starts_with("site_"):start_pos)
```


Now that we have our recipe we can build our model and fit it:

```{r eval=TRUE, echo=TRUE}
#Next, construct your model object
lm_rank_mod_start_pos_race_num <- 
  linear_reg() %>% 
  set_engine("lm")

marbles_rank_wkflow <- 
  workflow() %>% 
  add_model(lm_rank_mod_start_pos_race_num) %>% 
  add_recipe(marbles_rank_rec)

marbles_rank_wkflow

marbles_rank_fit <- 
  marbles_rank_wkflow %>% 
  fit(data = start_and_finish)

marbles_rank_fit %>% 
  pull_workflow_fit() %>% 
  tidy()
```
Now that we consider starting position, the site of the race, and the interaction of those two, the previous significant effect of starting position disappears. Adding these extra terms changes how each of the coefficients are interpreted. When only one variable is considered (starting position) in a simple regression, that variable is considered to be the sole effector of the response variable. But when we include other relevant information about the races we see that starting position doesn't have that much of an effect on the finishing place of a team in race. 
